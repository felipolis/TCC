{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## SEPARANDO ENTRE DADOS DE TREINO E TESTE ##############\n",
    "\n",
    "# Pega as duas primeiras colunas (key, nome_arqivo) do arquivo LBP.csv\n",
    "df = pd.read_csv('./data/caracteristicas/LBP.csv', usecols=[0,1])\n",
    "\n",
    "# Remove as linhas onde há um nome_arquivo repetido\n",
    "df = df.drop_duplicates(subset=['nome_arquivo'])\n",
    "\n",
    "# Remova o elemento em que só há uma ocorrência de classe\n",
    "df = df.groupby('key').filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Coloca a coluna key em uma lista chamada classes e a coluna nome_arquivo em uma lista chamada arquivos\n",
    "classes = df['key'].tolist()\n",
    "arquivos = df['nome_arquivo'].tolist()\n",
    "\n",
    "# Separe quais arquivos serão usados para treino e quais serão usados para teste\n",
    "arquivos_treino, arquivos_teste, classes_treino, classes_teste = train_test_split(arquivos, classes, test_size=0.2, random_state=42, stratify=classes)\n",
    "\n",
    "# Carregar o arquivo LBP.csv\n",
    "df_lbp = pd.read_csv('./data/caracteristicas/LBP.csv')\n",
    "\n",
    "# Selecionar apenas as linhas que estão nos arquivos de treino\n",
    "df_lbp_treino = df_lbp[df_lbp['nome_arquivo'].isin(arquivos_treino)]\n",
    "\n",
    "# Selecionar apenas as linhas que estão nos arquivos de teste\n",
    "df_lbp_teste = df_lbp[df_lbp['nome_arquivo'].isin(arquivos_teste)]\n",
    "\n",
    "# Separa entre y_treino e X_treino\n",
    "y_treino = df_lbp_treino['key'].values\n",
    "X_treino = df_lbp_treino.drop(['key', 'nome_arquivo'], axis=1).values\n",
    "\n",
    "# Separa entre y_teste e X_teste\n",
    "y_teste = df_lbp_teste['key'].values\n",
    "X_teste = df_lbp_teste.drop(['key', 'nome_arquivo'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## NORMALIZANDO OS DADOS ##############\n",
    "\n",
    "# Cria um objeto para normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normaliza os dados de treino\n",
    "scaler.fit(X_treino)\n",
    "X_treino = scaler.transform(X_treino)\n",
    "\n",
    "# Normaliza os dados de teste\n",
    "scaler.fit(X_teste)\n",
    "X_teste = scaler.transform(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TRATANDO OS VALORES NAN ##############\n",
    "\n",
    "# Substitui os valores NaN por 0\n",
    "X_treino = np.nan_to_num(X_treino)\n",
    "X_teste = np.nan_to_num(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=17)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## TREINANDO O MODELO ##############\n",
    "\n",
    "# Cria um objeto para o classificador KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "\n",
    "# Treina o modelo\n",
    "knn.fit(X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     abethr1       0.00      0.00      0.00        11\n",
      "     abhori1       0.06      0.09      0.08       140\n",
      "     abythr1       0.00      0.00      0.00        17\n",
      "     afbfly1       0.00      0.00      0.00        14\n",
      "     afdfly1       0.00      0.00      0.00        21\n",
      "     afecuc1       0.00      0.00      0.00        54\n",
      "     affeag1       0.12      0.06      0.08        16\n",
      "     afgfly1       0.00      0.00      0.00         5\n",
      "     afghor1       0.00      0.00      0.00        51\n",
      "     afmdov1       0.00      0.00      0.00        24\n",
      "     afpfly1       0.02      0.02      0.02        95\n",
      "     afpwag1       0.01      0.01      0.01        68\n",
      "     afrgos1       0.24      0.28      0.26        81\n",
      "     afrgrp1       0.00      0.00      0.00        17\n",
      "     afrjac1       0.00      0.00      0.00        16\n",
      "     afrthr1       0.03      0.03      0.03        66\n",
      "     amesun2       0.00      0.00      0.00        33\n",
      "     augbuz1       0.00      0.00      0.00         6\n",
      "     bagwea1       0.00      0.00      0.00        18\n",
      "      barswa       0.15      0.27      0.19       546\n",
      "     bawhor2       0.01      0.04      0.02        24\n",
      "     bawman1       0.00      0.00      0.00         2\n",
      "     bcbeat1       0.03      0.02      0.02        51\n",
      "     beasun2       0.00      0.00      0.00        39\n",
      "     bkctch1       0.01      0.01      0.01        85\n",
      "     bkfruw1       0.00      0.00      0.00        18\n",
      "     blacra1       0.03      0.02      0.03        44\n",
      "     blacuc1       0.00      0.00      0.00        78\n",
      "     blakit1       0.07      0.16      0.10       216\n",
      "     blaplo1       0.00      0.00      0.00        45\n",
      "     blbpuf2       0.01      0.01      0.01       106\n",
      "     blcapa2       0.00      0.00      0.00        17\n",
      "     blfbus1       0.01      0.03      0.02        32\n",
      "     blhgon1       0.09      0.03      0.05        30\n",
      "     blhher1       0.00      0.00      0.00         5\n",
      "     blksaw1       0.00      0.00      0.00         4\n",
      "     blnmou1       0.00      0.00      0.00        23\n",
      "     blnwea1       0.00      0.00      0.00        10\n",
      "     bltapa1       0.00      0.00      0.00         5\n",
      "     bltbar1       0.00      0.00      0.00         1\n",
      "     bltori1       0.00      0.00      0.00        19\n",
      "     blwlap1       0.00      0.00      0.00         8\n",
      "     brcale1       0.00      0.00      0.00         5\n",
      "     brcsta1       0.00      0.00      0.00         5\n",
      "     brctch1       0.00      0.00      0.00        40\n",
      "     brican1       0.00      0.00      0.00        28\n",
      "     brobab1       0.00      0.00      0.00        40\n",
      "     broman1       0.00      0.00      0.00        20\n",
      "     brosun1       0.00      0.00      0.00        13\n",
      "     brrwhe3       0.14      0.17      0.15         6\n",
      "     brubru1       0.02      0.02      0.02        53\n",
      "     brwwar1       0.00      0.00      0.00        30\n",
      "     bswdov1       0.00      0.00      0.00        38\n",
      "     btweye2       0.02      0.03      0.02        72\n",
      "     bubwar2       0.00      0.00      0.00         6\n",
      "     butapa1       0.00      0.00      0.00        28\n",
      "     cabgre1       0.04      0.06      0.05        18\n",
      "     carcha1       0.07      0.07      0.07       171\n",
      "     carwoo1       0.00      0.00      0.00        27\n",
      "      categr       0.16      0.20      0.18       217\n",
      "     ccbeat1       0.00      0.00      0.00         9\n",
      "     chespa1       0.00      0.00      0.00         2\n",
      "     chewea1       0.00      0.00      0.00         7\n",
      "     chibat1       0.02      0.01      0.01       103\n",
      "     chtapa3       0.00      0.00      0.00        25\n",
      "     chucis1       0.00      0.00      0.00        22\n",
      "     cibwar1       0.08      0.06      0.07       114\n",
      "     cohmar1       0.07      0.11      0.08       492\n",
      "     colsun2       0.19      0.24      0.21       182\n",
      "     combul2       0.03      0.04      0.04       319\n",
      "     combuz1       0.08      0.14      0.10       540\n",
      "      comsan       0.08      0.12      0.09       328\n",
      "     crheag1       0.00      0.00      0.00        20\n",
      "     crohor1       0.00      0.00      0.00        46\n",
      "     darbar1       0.00      0.00      0.00        17\n",
      "     darter3       0.00      0.00      0.00         4\n",
      "     didcuc1       0.03      0.02      0.02        65\n",
      "     dotbar1       0.00      0.00      0.00         2\n",
      "     dutdov1       0.00      0.00      0.00         6\n",
      "     easmog1       0.00      0.00      0.00         9\n",
      "     eaywag1       0.08      0.09      0.09       437\n",
      "     edcsun3       0.00      0.00      0.00        13\n",
      "      egygoo       0.02      0.01      0.01        83\n",
      "     equaka1       0.00      0.00      0.00         2\n",
      "     eswdov1       0.00      0.00      0.00        51\n",
      "     eubeat1       0.33      0.34      0.34       966\n",
      "     fatrav1       0.00      0.00      0.00         9\n",
      "     fatwid1       0.00      0.00      0.00         4\n",
      "     fislov1       0.00      0.00      0.00         7\n",
      "     fotdro5       0.04      0.05      0.04       154\n",
      "     gabgos2       0.00      0.00      0.00        27\n",
      "      gargan       0.15      0.09      0.11        78\n",
      "     gbesta1       0.00      0.00      0.00        42\n",
      "     gnbcam2       0.03      0.02      0.03       201\n",
      "     gnhsun1       0.00      0.00      0.00        24\n",
      "     gobbun1       0.02      0.01      0.01        88\n",
      "     gobsta5       0.00      0.00      0.00         2\n",
      "     gobwea1       0.00      0.00      0.00         2\n",
      "     grbcam1       0.02      0.01      0.01       107\n",
      "     grccra1       0.00      0.00      0.00         3\n",
      "      grecor       0.00      0.00      0.00        97\n",
      "      greegr       0.01      0.01      0.01       127\n",
      "     grewoo2       0.16      0.06      0.09       103\n",
      "     grwpyt1       0.00      0.00      0.00        19\n",
      "     gryapa1       0.00      0.00      0.00        24\n",
      "     grywrw1       0.00      0.00      0.00        13\n",
      "     gybfis1       0.00      0.00      0.00         7\n",
      "     gycwar3       0.08      0.02      0.03        47\n",
      "     gyhbus1       0.02      0.02      0.02        63\n",
      "     gyhkin1       0.00      0.00      0.00        24\n",
      "     gyhneg1       0.00      0.00      0.00         8\n",
      "     gyhspa1       0.04      0.02      0.03        47\n",
      "     gytbar1       0.00      0.00      0.00         3\n",
      "     hadibi1       0.14      0.06      0.08        90\n",
      "     hamerk1       0.00      0.00      0.00        20\n",
      "     hartur1       0.00      0.00      0.00        11\n",
      "      helgui       0.00      0.00      0.00        47\n",
      "     hipbab1       0.00      0.00      0.00        11\n",
      "      hoopoe       0.09      0.13      0.10       550\n",
      "     huncis1       0.00      0.00      0.00         7\n",
      "     hunsun2       0.00      0.00      0.00         8\n",
      "     joygre1       0.00      0.00      0.00         1\n",
      "     kerspa2       0.00      0.00      0.00        37\n",
      "     klacuc1       0.02      0.03      0.03        36\n",
      "     kvbsun1       0.00      0.00      0.00         6\n",
      "     laudov1       0.06      0.03      0.04        97\n",
      "      lawgol       0.02      0.04      0.03        96\n",
      "     lesmaw1       0.00      0.00      0.00        18\n",
      "     lessts1       0.00      0.00      0.00        15\n",
      "     libeat1       0.00      0.00      0.00         7\n",
      "      litegr       0.05      0.03      0.04       242\n",
      "     litswi1       0.48      0.26      0.34       193\n",
      "     litwea1       0.00      0.00      0.00        23\n",
      "     loceag1       0.00      0.00      0.00        14\n",
      "     lotlap1       0.00      0.00      0.00         1\n",
      "     luebus1       0.00      0.00      0.00        16\n",
      "     mabeat1       0.00      0.00      0.00         7\n",
      "     macshr1       0.00      0.00      0.00         5\n",
      "     malkin1       0.00      0.00      0.00         8\n",
      "     marsto1       0.00      0.00      0.00        13\n",
      "     marsun2       0.00      0.00      0.00        39\n",
      "     mcptit1       0.00      0.00      0.00         8\n",
      "     meypar1       0.00      0.00      0.00        34\n",
      "     moccha1       0.00      0.00      0.00       117\n",
      "     mouwag1       0.00      0.00      0.00        36\n",
      "     ndcsun2       0.00      0.00      0.00        22\n",
      "     nobfly1       0.00      0.00      0.00         7\n",
      "     norbro1       0.00      0.00      0.00        16\n",
      "     norcro1       0.00      0.00      0.00        28\n",
      "     norfis1       0.00      0.00      0.00        11\n",
      "     norpuf1       0.00      0.00      0.00        16\n",
      "     nubwoo1       0.00      0.00      0.00         8\n",
      "     pabspa1       0.00      0.00      0.00         6\n",
      "     palfly2       0.00      0.00      0.00        11\n",
      "     palpri1       0.00      0.00      0.00         2\n",
      "     piecro1       0.00      0.00      0.00        69\n",
      "     piekin1       0.03      0.02      0.02        59\n",
      "      pitwhy       0.00      0.00      0.00        49\n",
      "     purgre2       0.00      0.00      0.00         3\n",
      "     pygbat1       0.00      0.00      0.00         4\n",
      "     quailf1       0.00      0.00      0.00        26\n",
      "     ratcis1       0.00      0.00      0.00       133\n",
      "     raybar1       0.00      0.00      0.00         7\n",
      "     rbsrob1       0.07      0.07      0.07       251\n",
      "     rebfir2       0.14      0.06      0.08        36\n",
      "     rebhor1       0.00      0.00      0.00        26\n",
      "     reboxp1       0.00      0.00      0.00        12\n",
      "      reccor       0.00      0.00      0.00        46\n",
      "     reccuc1       0.00      0.00      0.00        93\n",
      "     reedov1       0.00      0.00      0.00        45\n",
      "     refbar2       0.00      0.00      0.00        14\n",
      "     refcro1       0.00      0.00      0.00        31\n",
      "     reftin1       0.00      0.00      0.00        48\n",
      "     refwar2       0.00      0.00      0.00         7\n",
      "     rehwea1       0.00      0.00      0.00         6\n",
      "     reisee2       0.00      0.00      0.00        18\n",
      "     rerswa1       0.05      0.04      0.05       187\n",
      "     rewsta1       0.00      0.00      0.00        16\n",
      "      rindov       0.06      0.03      0.04        72\n",
      "     rocmar2       0.00      0.00      0.00        20\n",
      "     rostur1       0.00      0.00      0.00         4\n",
      "     ruegls1       0.00      0.00      0.00        35\n",
      "     rufcha2       0.00      0.00      0.00         3\n",
      "     sacibi2       0.00      0.00      0.00         4\n",
      "     sccsun2       0.00      0.00      0.00        62\n",
      "     scrcha1       0.00      0.00      0.00        24\n",
      "     scthon1       0.00      0.00      0.00        20\n",
      "     shesta1       0.00      0.00      0.00         7\n",
      "     sichor1       0.00      0.00      0.00        29\n",
      "     sincis1       0.05      0.03      0.04        36\n",
      "     slbgre1       0.00      0.00      0.00        18\n",
      "     slcbou1       0.05      0.03      0.04        32\n",
      "     sltnig1       0.00      0.00      0.00        27\n",
      "     sobfly1       0.00      0.00      0.00        14\n",
      "     somgre1       0.19      0.14      0.16       213\n",
      "     somtit4       0.00      0.00      0.00        13\n",
      "     soucit1       0.00      0.00      0.00        16\n",
      "     soufis1       0.00      0.00      0.00        40\n",
      "     spemou2       0.00      0.00      0.00        33\n",
      "     spepig1       0.00      0.00      0.00        29\n",
      "     spewea1       0.00      0.00      0.00         8\n",
      "     spfbar1       0.00      0.00      0.00         7\n",
      "     spfwea1       0.00      0.00      0.00         5\n",
      "     spmthr1       0.12      0.10      0.11        88\n",
      "     spwlap1       0.25      0.06      0.10        50\n",
      "     squher1       0.00      0.00      0.00        18\n",
      "      strher       0.00      0.00      0.00        39\n",
      "     strsee1       0.00      0.00      0.00        33\n",
      "     stusta1       0.00      0.00      0.00         2\n",
      "     subbus1       0.00      0.00      0.00        62\n",
      "     supsta1       0.00      0.00      0.00        41\n",
      "     tacsun1       0.00      0.00      0.00         6\n",
      "     tafpri1       0.04      0.02      0.03        93\n",
      "     tamdov1       0.25      0.17      0.20       151\n",
      "     thrnig1       0.29      0.42      0.34      1494\n",
      "     trobou1       0.00      0.00      0.00        91\n",
      "     varsun2       0.23      0.11      0.15        79\n",
      "     vibsta2       0.00      0.00      0.00        16\n",
      "     vilwea1       0.13      0.09      0.11        99\n",
      "     vimwea1       0.00      0.00      0.00        15\n",
      "     walsta1       0.00      0.00      0.00        31\n",
      "     wbgbir1       0.00      0.00      0.00        32\n",
      "     wbrcha2       0.02      0.01      0.01       123\n",
      "     wbswea1       0.21      0.04      0.06        82\n",
      "     wfbeat1       0.00      0.00      0.00        22\n",
      "     whbcan1       0.00      0.00      0.00        12\n",
      "     whbcou1       0.00      0.00      0.00        43\n",
      "     whbcro2       0.00      0.00      0.00         8\n",
      "     whbtit5       0.00      0.00      0.00        14\n",
      "     whbwea1       0.00      0.00      0.00         8\n",
      "     whbwhe3       0.12      0.10      0.11        30\n",
      "     whcpri2       0.00      0.00      0.00         5\n",
      "     wheslf1       0.00      0.00      0.00        13\n",
      "     whihel1       0.00      0.00      0.00        11\n",
      "     whrshr1       0.00      0.00      0.00         3\n",
      "     witswa1       0.00      0.00      0.00         1\n",
      "      wlwwar       0.14      0.13      0.13       840\n",
      "     wookin1       0.00      0.00      0.00        36\n",
      "      woosan       0.04      0.03      0.03       287\n",
      "     wtbeat1       0.00      0.00      0.00        13\n",
      "     yebapa1       0.05      0.02      0.03        58\n",
      "     yebbar1       0.00      0.00      0.00        20\n",
      "     yebduc1       0.00      0.00      0.00         6\n",
      "     yebere1       0.00      0.00      0.00        32\n",
      "     yebgre1       0.00      0.00      0.00        24\n",
      "     yeccan1       0.00      0.00      0.00        16\n",
      "      yefcan       0.00      0.00      0.00        62\n",
      "     yelbis1       0.00      0.00      0.00        12\n",
      "     yenspu1       0.00      0.00      0.00         3\n",
      "     yertin1       0.01      0.01      0.01        85\n",
      "     yesbar1       0.00      0.00      0.00        26\n",
      "     yespet1       0.00      0.00      0.00        10\n",
      "     yetgre1       0.00      0.00      0.00        15\n",
      "     yewgre1       0.11      0.06      0.08        83\n",
      "\n",
      "    accuracy                           0.12     16512\n",
      "   macro avg       0.03      0.02      0.02     16512\n",
      "weighted avg       0.10      0.12      0.11     16512\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "############## TESTANDO O MODELO ##############\n",
    "\n",
    "# Testa o modelo\n",
    "y_pred = knn.predict(X_teste)\n",
    "\n",
    "# Exbe o relatório de classificação\n",
    "print(classification_report(y_teste, y_pred))\n",
    "\n",
    "# Criar um dataframe com as colunas 'key', 'nome_arquivo' e 'predicao'\n",
    "#df_pred = pd.DataFrame({'key': y_teste, 'nome_arquivo': arquivos_teste, 'predicao': y_pred})\n",
    "\n",
    "# print(len(y_teste))\n",
    "# print(len(arquivos_teste))\n",
    "# print(len(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
