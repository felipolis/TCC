{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## SEPARANDO ENTRE DADOS DE TREINO E TESTE ##############\n",
    "\n",
    "# Pega as duas primeiras colunas (key, nome_arqivo) do arquivo LBP.csv\n",
    "df = pd.read_csv('./data/caracteristicas/LBP.csv', usecols=[0,1])\n",
    "\n",
    "# Remove as linhas onde há um nome_arquivo repetido\n",
    "df = df.drop_duplicates(subset=['nome_arquivo'])\n",
    "\n",
    "# Remova o elemento em que só há uma ocorrência de classe\n",
    "df = df.groupby('key').filter(lambda x: len(x) > 1)\n",
    "\n",
    "# Coloca a coluna key em uma lista chamada classes e a coluna nome_arquivo em uma lista chamada arquivos\n",
    "classes = df['key'].tolist()\n",
    "arquivos = df['nome_arquivo'].tolist()\n",
    "\n",
    "# Separe quais arquivos serão usados para treino e quais serão usados para teste\n",
    "arquivos_treino, arquivos_teste, classes_treino, classes_teste = train_test_split(arquivos, classes, test_size=0.2, random_state=42, stratify=classes)\n",
    "\n",
    "# Carregar o arquivo LBP.csv\n",
    "df_lbp = pd.read_csv('./data/caracteristicas/LBP.csv')\n",
    "\n",
    "# Selecionar apenas as linhas que estão nos arquivos de treino\n",
    "df_lbp_treino = df_lbp[df_lbp['nome_arquivo'].isin(arquivos_treino)]\n",
    "\n",
    "# Selecionar apenas as linhas que estão nos arquivos de teste\n",
    "df_lbp_teste = df_lbp[df_lbp['nome_arquivo'].isin(arquivos_teste)]\n",
    "\n",
    "df_lbp_teste.head(20)\n",
    "\n",
    "# Separa entre y_treino e X_treino\n",
    "y_treino = df_lbp_treino['key'].values\n",
    "X_treino = df_lbp_treino.drop(['key', 'nome_arquivo'], axis=1).values\n",
    "\n",
    "# Separa entre y_teste e X_teste\n",
    "y_teste = df_lbp_teste['key'].values\n",
    "X_teste = df_lbp_teste.drop(['key', 'nome_arquivo'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## NORMALIZANDO OS DADOS ##############\n",
    "\n",
    "# Cria um objeto para normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normaliza os dados de treino\n",
    "X_treino = scaler.fit_transform(X_treino)\n",
    "\n",
    "# Normaliza os dados de teste\n",
    "X_teste = scaler.transform(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TRATANDO OS VALORES NAN ##############\n",
    "\n",
    "# Substitui os valores NaN por 0\n",
    "X_treino = np.nan_to_num(X_treino)\n",
    "X_teste = np.nan_to_num(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## TREINANDO O MODELO ##############\n",
    "\n",
    "# Cria um objeto para o classificador SVM\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "\n",
    "# Treina o modelo\n",
    "svm.fit(X_treino, y_treino)\n",
    "\n",
    "# Testa o modelo\n",
    "y_pred = svm.predict(X_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## VOTAÇÃO ##############\n",
    "\n",
    "# copie o df df_lbp_teste para df_lbp_teste_votacao e adicione a coluna 'predicao'\n",
    "df_lbp_teste_votacao = df_lbp_teste.copy()\n",
    "df_lbp_teste_votacao['predicao'] = y_pred\n",
    "\n",
    "# Faça a votação para cada nome_arquivo\n",
    "df_lbp_teste_votacao = df_lbp_teste_votacao.groupby('nome_arquivo')['predicao'].agg(lambda x:x.value_counts().index[0]).reset_index()\n",
    "\n",
    "# Crie um df com as classes reais\n",
    "df_lbp_teste_real = df_lbp_teste.drop_duplicates(subset=['nome_arquivo'])\n",
    "\n",
    "# Junte os dois df\n",
    "df_lbp_teste_real = df_lbp_teste_real.merge(df_lbp_teste_votacao, on='nome_arquivo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## AVALIANDO O MODELO ##############\n",
    "\n",
    "# Imprime o relatório de classificação\n",
    "print(classification_report(df_lbp_teste_real['key'], df_lbp_teste_real['predicao']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
